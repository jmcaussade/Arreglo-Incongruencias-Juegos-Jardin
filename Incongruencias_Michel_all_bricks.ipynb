{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+qgi/hW1pXSWLRu5A/Hql",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmcaussade/Arreglo-Incongruencias-Juegos-Jardin/blob/main/Incongruencias_Michel_all_bricks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Código con folder de archivos</h1>\n"
      ],
      "metadata": {
        "id": "AepbxYikWkot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "GcI5wAXlWYvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import xlsxwriter\n",
        "import unicodedata\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Functions\n",
        "def generate_colors(n):\n",
        "    \"\"\"Generate n distinct colors.\"\"\"\n",
        "    cmap = matplotlib.colormaps['tab20']\n",
        "    return [matplotlib.colors.to_hex(cmap(i/n)) for i in range(n)]\n",
        "\n",
        "def normalizar_texto(texto):\n",
        "    \"\"\"Normalize text - convert to lowercase and remove accents.\"\"\"\n",
        "    texto = texto.lower()\n",
        "    texto = unicodedata.normalize('NFD', texto).encode('ascii', 'ignore').decode(\"utf-8\")\n",
        "    return texto\n",
        "\n",
        "# Define the path of the uploaded zip file\n",
        "zip_file_path = 'Excel_Bricks.zip'  # Replace with the actual path\n",
        "\n",
        "# Define the target folder where you want to unzip\n",
        "target_folder = 'unzipped_folder'  # Replace with your desired target folder path\n",
        "\n",
        "# Unzip the folder\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(target_folder)\n",
        "\n",
        "# Use the unzipped folder as input_folder and create the output folder within it\n",
        "input_folder = os.path.join(target_folder, 'Excel_Bricks')\n",
        "output_folder = os.path.join(target_folder, 'Excel_Bricks_Clean')\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Get a list of all Excel files in the input folder\n",
        "excel_files = glob(os.path.join(input_folder, '*.xlsx'))\n",
        "print(f\"excel_files: {excel_files}\")\n",
        "for excel_file in excel_files:\n",
        "    print(excel_file)\n",
        "    # Read Excel File\n",
        "    df = pd.read_excel(excel_file, sheet_name='Hoja1')\n",
        "\n",
        "    # Preprocessing: Convert all columns to string and strip leading/trailing white spaces\n",
        "    df = df.applymap(lambda x: str(x).strip() if isinstance(x, str) else str(x))\n",
        "\n",
        "    # Define columns to exclude\n",
        "    excluir_columnas = [\"<ID>\", \"SKU - Chile\", \"Jefe de Línea\", 'Descripción Web', '<Name>', \"Marca\", \"Origen\", \"<Parent ID>\"]\n",
        "\n",
        "    # Generate colors for columns\n",
        "    initial_col_count = max(len(df.columns) - len(excluir_columnas), 1)\n",
        "    colores_columnas = generate_colors(initial_col_count)\n",
        "\n",
        "    # Process DataFrame\n",
        "    for i, col in enumerate(df.columns):\n",
        "        if col not in excluir_columnas:\n",
        "            insert_position = df.columns.get_loc(col) + 1\n",
        "            col_aparece = f\"{col} aparece\"\n",
        "\n",
        "            def calculate_aparece(row):\n",
        "                value = normalizar_texto(str(row[col]))\n",
        "                if value in normalizar_texto(str(row['<Name>'])) or value in normalizar_texto(str(row['Descripción Web'])):\n",
        "                  return 1  # Convert True to integer 1\n",
        "                else:\n",
        "                  return 0\n",
        "\n",
        "            df[col_aparece] = df.apply(calculate_aparece, axis=1)\n",
        "\n",
        "    # Fill NaN values with 0 in boolean columns\n",
        "    boolean_columns = [col for col in df.columns if 'aparece' in col]\n",
        "    df[boolean_columns] = df[boolean_columns].fillna(0).astype(int)\n",
        "\n",
        "    # Calculate Row-wise Error Percentage\n",
        "    df['Porcentaje correctitud (Row)'] = df[boolean_columns].apply(lambda row: (row.sum() * 100) / len(row), axis=1)\n",
        "\n",
        "    # Create a DataFrame to hold the error percentages by column\n",
        "    error_percentages_col = pd.DataFrame({col: [(df[col].sum() * 100) / len(df[col])] for col in boolean_columns})\n",
        "\n",
        "    # Save the exported file in the output folder with a unique name\n",
        "    output_file = os.path.join(output_folder, f'result_{os.path.basename(excel_file)}')\n",
        "    writer = pd.ExcelWriter(output_file, engine='xlsxwriter')\n",
        "    df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
        "\n",
        "    # Formatting and other code for this file...\n",
        "    # Formatting\n",
        "    workbook = writer.book\n",
        "    worksheet = writer.sheets['Sheet1']\n",
        "    format_verdadero = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})\n",
        "    format_falso = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})\n",
        "\n",
        "    for col_num, value in enumerate(df.columns.values):\n",
        "        if value not in excluir_columnas and 'aparece' not in value:\n",
        "            color_index = (col_num // 2) % len(colores_columnas)\n",
        "            cell_format = workbook.add_format({'bg_color': colores_columnas[color_index]})\n",
        "            worksheet.set_column(col_num, col_num, None, cell_format)\n",
        "        elif 'aparece' in value:\n",
        "            worksheet.conditional_format(1, col_num, len(df), col_num,\n",
        "                                        {'type': 'cell',\n",
        "                                          'criteria': '=',\n",
        "                                          'value': 1,  # Use integer 1 instead of True\n",
        "                                          'format': format_verdadero})\n",
        "            worksheet.conditional_format(1, col_num, len(df), col_num,\n",
        "                                        {'type': 'cell',\n",
        "                                          'criteria': '=',\n",
        "                                          'value': 0,  # Use integer 0 instead of False\n",
        "                                          'format': format_falso})\n",
        "\n",
        "    # Find the index of the first boolean column\n",
        "    first_boolean_col_index = df.columns.get_loc(boolean_columns[0])\n",
        "\n",
        "    # Add Error Percentages by Column starting from the first boolean column\n",
        "    for i, col in enumerate(boolean_columns):\n",
        "        col_offset = first_boolean_col_index + i  # Calculate the column offset\n",
        "        for j, value in enumerate(error_percentages_col[col].values):\n",
        "            worksheet.write(len(df) + 1 + j, col_offset, value if not np.isnan(value) else \"NaN\")\n",
        "\n",
        "    # Add \"Error Percentage by Attribute\" in the first cell of the row after the data ends\n",
        "    worksheet.write(len(df) + 1, 0, \"Porcentaje correctitud por Attribute\")\n",
        "\n",
        "    # Close and save Excel writer for this file\n",
        "    writer.close()\n",
        "\n",
        "# End of loop through Excel files\n",
        "print(\"All files processed and saved in the output folder.\")\n",
        "\n",
        "# Zip the entire output folder\n",
        "shutil.make_archive(output_folder, 'zip', output_folder)\n",
        "\n",
        "print(f\"Output folder zipped as {output_folder}.zip\")\n"
      ],
      "metadata": {
        "id": "R2zDbOkmW60t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04449d06-1d42-4a14-9362-4db3043a9114"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "excel_files: ['unzipped_folder/Excel_Bricks/Televisores 1400.xlsx', 'unzipped_folder/Excel_Bricks/Cemento 2526.xlsx', 'unzipped_folder/Excel_Bricks/Hidrolavadoras.xlsx', 'unzipped_folder/Excel_Bricks/Analisis.xlsx']\n",
            "unzipped_folder/Excel_Bricks/Televisores 1400.xlsx\n",
            "unzipped_folder/Excel_Bricks/Cemento 2526.xlsx\n",
            "unzipped_folder/Excel_Bricks/Hidrolavadoras.xlsx\n",
            "unzipped_folder/Excel_Bricks/Analisis.xlsx\n",
            "All files processed and saved in the output folder.\n",
            "Output folder zipped as unzipped_folder/Excel_Bricks_Clean.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>DISPLAY FILE </h1>\n"
      ],
      "metadata": {
        "id": "eygwPSC8JOkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_excel_file.xlsx' with the path to your Excel file\n",
        "# and 'Sheet1' with the name of the sheet you want to display\n",
        "\n",
        "file_path = 'unzipped_folder/Excel_Bricks_Clean/result_Analisis.xlsx'\n",
        "sheet_name = 'Sheet1'\n",
        "# file_path = 'Analisis.xlsx'\n",
        "# sheet_name = 'Hoja1'\n",
        "\n",
        "\n",
        "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
        "\n",
        "# Display the DataFrame\n",
        "# You can use df.head() to display the first few rows\n",
        "# or df to display the entire DataFrame (be cautious with large DataFrames)\n",
        "df\n"
      ],
      "metadata": {
        "id": "Nv6MRMYcIfa6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}